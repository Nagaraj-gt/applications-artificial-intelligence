{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76efe86ac7b74f3e8574b5206c47935a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d737bedccd34ce88909592189ab10b5",
              "IPY_MODEL_3251626c481740cfbafe2cb58ca1096a",
              "IPY_MODEL_26f8ce358e6f4092a45825791a75f707"
            ],
            "layout": "IPY_MODEL_3328ad5c765c401aa109d6a25cd2d9af"
          }
        },
        "4d737bedccd34ce88909592189ab10b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f2f305639e4508841beb02ce7ecbe2",
            "placeholder": "​",
            "style": "IPY_MODEL_d521206253e242ee830894594dd60648",
            "value": "100%"
          }
        },
        "3251626c481740cfbafe2cb58ca1096a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dacd3329a50d46699bfcb00c4ef95170",
            "max": 574673361,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5783d3823144896aaddb9b085f89992",
            "value": 574673361
          }
        },
        "26f8ce358e6f4092a45825791a75f707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d5f0e635d604923a7632904c9764163",
            "placeholder": "​",
            "style": "IPY_MODEL_2388c58a335947d592bf2208f1672cbc",
            "value": " 548M/548M [00:07&lt;00:00, 77.3MB/s]"
          }
        },
        "3328ad5c765c401aa109d6a25cd2d9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f2f305639e4508841beb02ce7ecbe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d521206253e242ee830894594dd60648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dacd3329a50d46699bfcb00c4ef95170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5783d3823144896aaddb9b085f89992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d5f0e635d604923a7632904c9764163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2388c58a335947d592bf2208f1672cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nagaraj-gt/applications-artificial-intelligence/blob/main/q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicized text*# PART B (3) : Image Classification\n",
        "\n",
        "***Finetune the vgg19 model on this dataset, train a 15-class classification model and report \n",
        "per-class classification accuracy in terms of precision and recall. \n",
        " Submit q2.py. [10 marks]***\n",
        "\n",
        "\n",
        "\n",
        "**TEAM MEMBERS:**\n",
        "\n",
        " Nagaraj G T\t 12120095\n",
        "\n",
        " Yashaswi Singh\t 12120064\n",
        "\n",
        " Madhab Chakraborty\t 12120045\n",
        "\n",
        " Rama Gangadhar Durvasula\t 12120087\n",
        "\n",
        " Parmarth matta\t 12120077\n",
        "\n"
      ],
      "metadata": {
        "id": "JeWM8DJ0lcyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T3xlOgIAkeS5"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, models, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre=processing the input images to match images with what was presented during training period\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )])"
      ],
      "metadata": {
        "id": "k3QsPWTXjq75"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Train and Test Images. The Assignment data is split into train (1 to 40) and validation (rest) sets manually and uploaded in GIT\n",
        "\n",
        "!wget 'https://github.com/Nagaraj-gt/applications-artificial-intelligence/raw/main/dataset.zip'\n",
        "!unzip dataset.zip\n"
      ],
      "metadata": {
        "id": "_NCz9q7DkaMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries for training\n",
        "\n",
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "UgnWYuDizohU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "g26dVGJZQmMB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/dataset'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcPZIRIExu1O",
        "outputId": "840e2410-5a97-43b1-f5db-9a73fdb717f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to train pre-trained model with domain specific data\n",
        "import copy\n",
        "import time\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "nhvkWVIHCQ-q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to visualize Model Predictions\n",
        "\n",
        "# Visualize few images\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "IN-uk_kEC0SD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG 19 Model\n"
      ],
      "metadata": {
        "id": "1lHAaqOpdWfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pretrained VGG Model and reset final fully connected Layer for training\n",
        "\n",
        "vgg_model = models.vgg19(pretrained=True)\n",
        "num_ftrs = vgg_model.classifier[0].in_features\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "vgg_model.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft = vgg_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "76efe86ac7b74f3e8574b5206c47935a",
            "4d737bedccd34ce88909592189ab10b5",
            "3251626c481740cfbafe2cb58ca1096a",
            "26f8ce358e6f4092a45825791a75f707",
            "3328ad5c765c401aa109d6a25cd2d9af",
            "61f2f305639e4508841beb02ce7ecbe2",
            "d521206253e242ee830894594dd60648",
            "dacd3329a50d46699bfcb00c4ef95170",
            "f5783d3823144896aaddb9b085f89992",
            "7d5f0e635d604923a7632904c9764163",
            "2388c58a335947d592bf2208f1672cbc"
          ]
        },
        "outputId": "ab439a9f-2178-45dc-b3bc-4cb9210e97a5",
        "id": "nFSddNO1d0E5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76efe86ac7b74f3e8574b5206c47935a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6737200-0bed-4461-bff6-b1d3353ce425",
        "id": "5x4f8WsAd75q"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 3.7005 Acc: 0.0650\n",
            "val Loss: 3.0080 Acc: 0.1122\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 2.7745 Acc: 0.1567\n",
            "val Loss: 2.3781 Acc: 0.2390\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 2.3941 Acc: 0.2567\n",
            "val Loss: 2.1521 Acc: 0.2732\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 1.8525 Acc: 0.4133\n",
            "val Loss: 1.8537 Acc: 0.4293\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 1.6684 Acc: 0.4983\n",
            "val Loss: 1.2780 Acc: 0.5951\n",
            "\n",
            "Training complete in 1m 53s\n",
            "Best val Acc: 0.595122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Per class classification accuracy report in terms of precision and recall\n",
        "\n",
        "import pandas as pd\n",
        "def print_accuracy_matrix(model):\n",
        "  nb_classes = 15\n",
        "\n",
        "  confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "  with torch.no_grad():\n",
        "      for i, (inputs, classes) in enumerate(dataloaders['val']):\n",
        "          inputs = inputs.to(device)\n",
        "          classes = classes.to(device)\n",
        "          \n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          for t, p in zip(classes.view(-1), preds.view(-1)): \n",
        "                  confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "  precision = confusion_matrix.diag()/confusion_matrix.sum(1)\n",
        "  recall = confusion_matrix.diag()/confusion_matrix.sum(0)\n",
        "  res_accuracy = pd.DataFrame(list(zip(class_names,precision.tolist(), recall.tolist())), columns=['Class', 'Precision', 'Recall'])\n",
        "\n",
        "  print(res_accuracy)"
      ],
      "metadata": {
        "id": "NMPwTLCrnEFw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy_matrix(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6EDe-1d5jja",
        "outputId": "69c66c3d-62c1-4abf-bcc1-a51bec543f97"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Class  Precision    Recall\n",
            "0        accordion   1.000000  1.000000\n",
            "1             bass   0.571429  0.533333\n",
            "2           camera   1.000000  0.833333\n",
            "3        crocodile   0.700000  0.388889\n",
            "4   crocodile_head   0.000000       NaN\n",
            "5              cup   0.176471  1.000000\n",
            "6      dollar_bill   1.000000  0.375000\n",
            "7              emu   0.692308  0.600000\n",
            "8       gramophone   1.000000  0.333333\n",
            "9         hedgehog   0.785714  0.611111\n",
            "10        nautilus   0.266667  1.000000\n",
            "11           pizza   0.384615  1.000000\n",
            "12         pyramid   0.294118  1.000000\n",
            "13       sea_horse   0.352941  0.545455\n",
            "14   windsor_chair   1.000000  0.842105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONCLUSION : The accuracy of VGG19 is about 72 - 75%. \n",
        "\n",
        "The accuracy is around 100% for precision and recall for certain classes like accordion and windsor_chair. However crocodile , bass its pretty bad !\n",
        "\n",
        "THis model needs to be fine tuned !\n"
      ],
      "metadata": {
        "id": "XFMTAgFpi3Vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINETUNING OF VGG 19 MODEL FOR BETTER ACCURACIES"
      ],
      "metadata": {
        "id": "anJnT1FQBRZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finetuning by Gradual unfreeze of the VGG layers to increase accuracy cannot be adopted. We have initially adopted strategy to train all layers and not just the final FC layer. The pretrained value is derived only to initialize the weights from pre-trained model rather than random**"
      ],
      "metadata": {
        "id": "NSDLyjjNF0tN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution 1 : Increase Epochs during training time"
      ],
      "metadata": {
        "id": "Lu_afk0WBsH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EXfNwewBdqp",
        "outputId": "7e34256c-81f4-4681-f589-ca2a2969dbca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.2583 Acc: 0.6050\n",
            "val Loss: 0.7328 Acc: 0.7463\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.9617 Acc: 0.7067\n",
            "val Loss: 0.4727 Acc: 0.8390\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.5877 Acc: 0.8250\n",
            "val Loss: 0.4099 Acc: 0.8683\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.4973 Acc: 0.8233\n",
            "val Loss: 0.3463 Acc: 0.8878\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.4914 Acc: 0.8333\n",
            "val Loss: 0.3267 Acc: 0.9024\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.4027 Acc: 0.8533\n",
            "val Loss: 0.3190 Acc: 0.8976\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.3919 Acc: 0.8567\n",
            "val Loss: 0.3029 Acc: 0.9024\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.3799 Acc: 0.8883\n",
            "val Loss: 0.3066 Acc: 0.8927\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.3723 Acc: 0.8683\n",
            "val Loss: 0.2916 Acc: 0.9073\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.3578 Acc: 0.8817\n",
            "val Loss: 0.2783 Acc: 0.9073\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.3375 Acc: 0.8850\n",
            "val Loss: 0.2734 Acc: 0.9073\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.2549 Acc: 0.9167\n",
            "val Loss: 0.2716 Acc: 0.9122\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.3155 Acc: 0.8983\n",
            "val Loss: 0.2625 Acc: 0.9122\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.3107 Acc: 0.9083\n",
            "val Loss: 0.2637 Acc: 0.9073\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.2647 Acc: 0.9050\n",
            "val Loss: 0.2579 Acc: 0.9171\n",
            "\n",
            "Training complete in 5m 14s\n",
            "Best val Acc: 0.917073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the best value accuracy with increased Epochs os 0.93. This is indeed good. "
      ],
      "metadata": {
        "id": "fakMDWb6EYcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy_matrix(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0RsGv7fEkLy",
        "outputId": "2f079967-f8df-4967-f0ce-39497fafe6cd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Class  Precision    Recall\n",
            "0        accordion   1.000000  0.937500\n",
            "1             bass   0.928571  0.866667\n",
            "2           camera   1.000000  1.000000\n",
            "3        crocodile   0.700000  0.777778\n",
            "4   crocodile_head   0.727273  0.727273\n",
            "5              cup   1.000000  1.000000\n",
            "6      dollar_bill   1.000000  1.000000\n",
            "7              emu   1.000000  0.928571\n",
            "8       gramophone   1.000000  0.733333\n",
            "9         hedgehog   0.928571  0.928571\n",
            "10        nautilus   0.933333  1.000000\n",
            "11           pizza   1.000000  0.928571\n",
            "12         pyramid   0.823529  1.000000\n",
            "13       sea_horse   0.823529  0.933333\n",
            "14   windsor_chair   0.875000  0.933333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy matrix for precision and recall has significantly increased for per class accuracies."
      ],
      "metadata": {
        "id": "BhzwLNTbEoWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution 2 : Decrease learning rate"
      ],
      "metadata": {
        "id": "wcL6021ZGoG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Optimize at 1/10th slow learning rate"
      ],
      "metadata": {
        "id": "wbWTpZIMP7do"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observe that all parameters are being optimized\n",
        "slow_optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "slow_exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "ZxxSumaGQALH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slow_model_ft = train_model(model_ft, criterion, slow_optimizer_ft, slow_exp_lr_scheduler,num_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CgHy8EhQsfV",
        "outputId": "e9c1106e-3ae4-4f78-ac47-d2249aca6b66"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/4\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3146 Acc: 0.8933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.2448 Acc: 0.9268\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.2831 Acc: 0.8950\n",
            "val Loss: 0.2562 Acc: 0.9024\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 0.2781 Acc: 0.9100\n",
            "val Loss: 0.2285 Acc: 0.9317\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 0.3608 Acc: 0.8850\n",
            "val Loss: 0.2156 Acc: 0.9317\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.2661 Acc: 0.8967\n",
            "val Loss: 0.2173 Acc: 0.9122\n",
            "\n",
            "Training complete in 1m 45s\n",
            "Best val Acc: 0.931707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_accuracy_matrix(slow_model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2ULBTE5Q-Db",
        "outputId": "44cce10b-c760-4d87-c98c-a65a9314ef80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Class  Precision    Recall\n",
            "0        accordion   1.000000  1.000000\n",
            "1             bass   0.928571  0.928571\n",
            "2           camera   1.000000  1.000000\n",
            "3        crocodile   0.800000  0.727273\n",
            "4   crocodile_head   0.727273  0.800000\n",
            "5              cup   1.000000  1.000000\n",
            "6      dollar_bill   1.000000  1.000000\n",
            "7              emu   1.000000  0.928571\n",
            "8       gramophone   1.000000  0.733333\n",
            "9         hedgehog   1.000000  0.933333\n",
            "10        nautilus   1.000000  1.000000\n",
            "11           pizza   0.923077  1.000000\n",
            "12         pyramid   0.941176  0.941176\n",
            "13       sea_horse   0.823529  1.000000\n",
            "14   windsor_chair   0.812500  0.928571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONCLUSION\n",
        "\n",
        "The fine tuning with either increased Epochs or slow learning rates results in better accuracy about 93%.\n",
        "\n",
        "The accuracy matrix of precision and Recall is marginally better with slow running rate, especially crocodile.\n",
        "\n",
        "Next step of improvement would be to further reduce learning rate with higher epochs , may be, 25."
      ],
      "metadata": {
        "id": "UWlkk75US1vN"
      }
    }
  ]
}